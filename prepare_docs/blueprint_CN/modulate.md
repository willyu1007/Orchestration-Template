# 模块化开发

我们认为通过限制任何单个操作的范围可以提高AI上下文管理效率。为使人类开发者和AI代理都能在清晰的边界内工作，我们将模块化开发作为基础原则，鼓励将仓库被结构化为定义良好、松散耦合的模块。

我们围绕模块化开发设计了整套的相关规范，用来以模块为单位管理基础设施（如知识/功能路由等）。也就是说，模块是构成项目的基础单元，同时也是其他主要基础体系的唯一载体，需要自行维护独立的配置、策略、工作记录、和代码实现。并维护自身允许使用的功能路由和知识路由。

和模块相关的概念主要有三个： module_level（层级）、module_type（类型）、module_entity（实例）
-  **模块实例**是面向业务的，是实际开发的唯一载体，前端/后端/逻辑的实现都需要对应到模块实例：
   -  `modules/` 目录中的具体模块
   -  AI工作过程的记录按实例维护，即`workdocs\`
   -  所有能力和代码都在模块实例的上下文中运行
   -  实例需要明确自身的策略、知识、路由等，以保证基础体系的可运行
-  **模块类型**是用来描述业务流和数据流，类型间的调用/依赖关系，组成图结构：
   -  模块的抽象分类，是具有执行一致性的运行模式
   -  模版将维护类型的串联关系，是系统运行和数据流转的蓝图
   -  实例可以声明其他模块的依赖，但这种依赖关系受到类型关系的约束
-  **模块级别**和类型是解耦的，层级描述实例的组成/包含关系，构成关系树：
   -  模块实例可以组织在父子树中，每个模块实例包含`module_level`，并可以指向 `parent_module`
   -  层次结构可以反应业务分解，是开发需求的逻辑梳理的产物
   -  关系树用于人类理解系统结构、合理化文档分组，但系统不会专门维护这种结构

---

## 1. 骨架结构及其用途

所有模块实例都有专属的目录，例如"/modules/<*mod_id>/"，本章节中，我们将使用**实例目录**来表示这个实例目录。

实例目录的典型骨架结构包括：
- 模块根目录中的核心AI文档：
  - `AGENTS.md`：实例的本地策略，用于定义AI开发时需要遵循的规范、需要了解的背景等，规则向上覆盖。
  - `ABILITY.md`：实例可以直接或间接调用的封装能力，用于告知AI可用工具，从而提高代码的规范程度和可控程度。
  - `ROUTING.md`：实例相关的顶层知识路由，给出实例开发过程中各情景下任务编排可能需要的路由，最终指向知识文档。
  - `MANIFEST.yaml`：实例的清单文件，捕获模块的关键元数据（其 module_type、对其他模块的任何依赖等）。
- 模块内容的标准子目录，例如：
  - `routes/`：承接顶层知识路由的具体路由，将根据不同情景提供不同的知识文档路径，详见<content_routing.md>。
  - `outcomes/`：开发过程中的产出物
  - `doc/`：用于额外的模块特定文档（指南、合同、模块特定的规范、人类阅读的文档等）。
  - `workdocs/`：用于模块特定的进行中笔记（尽管主要 workdocs 通常在仓库级别，模块特定任务可以在此处跟踪（如果需要））。
  - `config/`：用于模块配置文件。
  - 代码目录，可能包括 `backend/`、`frontend/`、`core/` 等，具体取决于技术（确切结构将遵循约定，例如Web模块可能有 `api/`或`service/` 目录）。

```
/module_instance/
├── AGENTS.md              # 策略文档
├── ROUNTING.md            # 顶层路由文档
├── ABILIIY.md             # 能力路由文档
├── workdocs/              # AI工作上下文目录
├── routes/                # 实际路由文档
├── config/                # 配置文件   
├── {code}/                # 可能包括 `backend/`、`frontend/`、`core/
├── interact/              # 实例的锲约、依赖、和影响（例如可能会改变数据库中某张表）     
├── docs/                  # 面向人类的文档（README、评估、observability等）       
└── MANIFEST.yaml          # 模块的关键元数据
    
```

### 代码目录
具体包含哪些目录取决于技术，确切结构将遵循约定。例如Web模块可能有 `api/`或`service/` 目录

### interact
- 数据库：需要哪些数据库中的数据（表、主键、字段），是否有写入、修改等操作
- 契约文件： scheme / contract
- mock、 fixture 或其它数据
- 其他

### workdocs
每个模块实例都需要维护工作记录，用以记录AI在执行任务过程中的所思所想和所作所为。骨架结构形如
``` 
workdocs/
├── AGENTS.md              # This file
├── active/                # Current work
│   ├── task-1/
│   │   ├── task-1-plan.md      # 完成任务的计划
│   │   ├── task-1-context.md   # 记录工作上下文
│   │   └── task-1-task.md      # 任务完成情况和进度   
│   └── task-2/
│       └── ...
├── outcome/               # 工作产出
│   ├── lessons.md         # 错误经验，避免再犯
│   ├── decisions.md       # 重要决策
│   └── scripts/           # 开发过程中新增的脚本
└── archive/               # Completed work (optional)
    ├── summary/           # 陈旧内容
    ├── old_tasks/         # 已完成的任务
        └── ...
```

---

## 2. 内容维护

我们先对`workdocs/`目录下的几个一目了然的文档和目录进行简要说明：
- `/AGENTS.md`：面向AI的使用手册。文档中将包含上下文的更新规范、使用建议、阅读顺序、写入要求等内容，这里我们仅给出要点概述
- `/archive/old_tasks/`：已完成任务归档后将存放在该目录下
- `/archive/summary/`：对于开发流程很长的任务，上下文中的陈旧信息将按照一定规则，总结后放入该目录。根据总行数、更新次数、时间等条件触发清理。

我们希望维护一套机制，帮助帮助AI完成思考->决策->执行->记录->回顾->思考的工作闭环。这是`workdocs`目录的设计初衷和核心作用：让AI通过阅读自己写入的信息，了解任务进度、避免重复犯错、回溯思考过程、以及查看运行效果。一个典型的闭环工作流程包括：
- 开始任务
  1. 检查是否和当前其他任务重复，确认无重复后在`active/`目录下创建任务目录和5个文档
  2. 根据需求，AI结合代码库深入思考，并将执行计划和阶段性需求写入`plan.md`和`task.md`;
  3. 检查计划是否合理，有没有考虑不周全的地方 
- 实施期间
  1. 参考`plan.md`了解整体策略
  2. 根据要求，定期更新`context.md`、`decisions.md`、`lessons.md`文档
  3. 根据检验标准，在`task.md`中勾选已完成的阶段/指标
- 上下文重置后
  1. AI重新读取`plan.md`、`context.md`、`task.md`
  2. 快速了解完整的任务执行状态，根据需求读取`decisions.md`、`lessons.md`
  3. 从上次中断的地方继续运行

### 2.1 AI运行上下文

作为项目开发的主力，AI的工作过程必须是可持续和可回溯的。在丢失上下文的情况下，AI需要可以快速掌握所需信息，而不是从头再来一遍。

接下来，我们将重点介绍  `workdocs/active/[task_name]/`目录。目录中包含三个主要的文档:`plan.md`、`context.md`、以及`task.md`，这些文档使用的基本原则如下
- **when to skip**: 没有难度的执行，如简单bug修复、细节修改、快速更新等
- **when to use**: 当工作可能跨session时，如当完成了一个复杂任务、完整的功能、重大重构时
- **update frequency**： 每次完成一个里程碑节点时，总结工作过程并更新文档
- **keep plan current**：每当任务范围发生变化，需要更新计划、添加新的阶段、记录原因。
- **make tasks actionable**：包含明确的文件名、清晰的验收标准、与其他任务的相关依赖等，eg: "Implement JWT token validation in AuthMiddleware.ts (Acceptance: Tokens validated, errors to Sentry)"

#### **plan.md**
AI需要在执行复杂任务前，将完成任务的思路和计划写入本文档，起到两个方面的作用：
  - 可以进行人工审核，决定是否需要调整计划
  - AI可以基于制定的计划，更新实施结果
建议写入文档的内容包括：执行摘要、现状分析、未来状态规划、实施阶段、包含验收标准的详细任务清单、风险评估、成功指标。当执行范围发生变化或进入/发现新的阶段时，AI应该及时更新本文档。

**Example:**
```markdown
# Feature Name - Implementation Plan
## Executive Summary
What we're building and why
## Current State
Where we are now
## Implementation Phases
### Phase 1: Infrastructure (2 hours)
- Task 1.1: Set up database schema
  - Acceptance: Schema compiles, relationships correct
- Task 1.2: Create service structure
  - Acceptance: All directories created
### Phase 2: Core Functionality (3 hours)
...
```
---

#### **context.md**

AI需要将恢复上下文的会用的关键信息写入文档，内容主要包括：任务进度、已完成与进行中的内容、关键文件及其用途、相关文件链接、以及快速恢复说明。在做出重大决策、完成关键节点、或重要发现后，需要更新此文档。鼓励高频率的更新此文档，特别是每次完成重要工作时，一定要更新“任务进度”部分！

**Example:**
```markdown
# Feature Name - Context
## SESSION PROGRESS (2025-10-29)
### COMPLETED
- Database schema created (User, Post, Comment models)
- PostController implemented with BaseController pattern
- Sentry integration working
### IN PROGRESS
- Creating PostService with business logic
- File: src/services/postService.ts
### BLOCKERS
- Need to decide on caching strategy
## Key Files
src/controllers/PostController.ts
- Extends BaseController
- Handles HTTP requests for posts
src/services/postService.ts (IN PROGRESS)
- Business logic for post operations
- Next: Add caching

## Quick Resume
To continue:
1. Read this file
2. Continue implementing PostService.createPost()
3. See tasks file for remaining work
```
---

#### **tasks.md**

本文档用于概述任务要求、以及通过清单管理的任务开发进度。

**Example:**
```markdown
# Feature Name - 
## Task Overview
- description: 
- current status:
- notice:

## Task Checklist
### Phase 1: Setup 
- [x] Create database schema
- [x] Set up controllers
- [x] Configure Sentry

### Phase 2: Implementation 
- [x] Create PostController
- [ ] Create PostService (IN PROGRESS)
- [ ] Create PostRepository
...

```

---

### 2.2 工作产出

相对于`active`目录外，`outcome`是上下文系统中另一个重要的目录。两者第一个显著的区别是：前者的作用域是单个任务，而后者是模块实例中的所有任务。另一个深层次的区别在于，`active`是面向AI工作过程的，核心用途为上下文恢复；而`outcome`即是产出说明，也是完善项目基础建设（如知识路由、能力路由等）的源头。

`outcome`目录包含两个文档，`decisions.md`、`lessons.md`，以及一个目录`scripts/`，分别对应知识/经验产物和功能/脚本产物
- 知识/经验：通过总结错误和跟错决策经验，项目可以不断积累知识。结合知识路由体系，AI在后续工作过程中将得到更准确的指引。
- 功能/脚本：实例功能逐渐完善的过程中，最主要的可复用的产出物是函数或脚本。这些脚本是功能路由（项目的重要基础设施，相当于AI的工具箱）的基石。

#### **decisions.md**
本文档用于记录AI执行过程的重要决定（如方案选择）、关键发现（如技术限制）、以及新增/删除文件（如新脚本、函数、接口等）。每条decision需要包含的条目包括：类型、概述、依据、造成的影响等

**Example:**
```markdown
# Decision
使用说明：规范AI的写入和更新时机、以及写入内容

## DECISION-001 (2025-11-08)
- type: file addition       # file deletion / decision / discovery
- description： ...         # 决策是要做什么
- reason：...               # 决策依据和逻辑
- influence：add <file>     # 影响了哪些层面（工作流）、或影响了哪些文档
- implemented：completed    # wait approval / processing / completed 
```

---
#### **lessons.md**

本文档用于记录AI执行过程中犯过的错误、造成的后果、相关教训、以及提醒。每条lesson信息需要包含完整的条目：带有状态（是否解决）、上下文的描述、错误主要原因、造成后果、教训总结、以及提醒/解决方案（可选）。

除列举具体错误外，文档还有以下两方面的内容：
- 使用说明：
- 错误索引：key=错误编号，value=简短描述，给出对应章节的链接或line （主要考虑AI使用的便捷程度）

**Example:**
```markdown
# Lessons
使用说明: 描述什么时候写入信息，需要写入哪些内容，在遇到错误的时候应该如何使用本文档
错误索引：错误编号以及错误的描述

## ERROR-001 (2025-11-08)
- status: solved
- summary: When updating modules/payments/api/contract, forgetting to update CONTRACT.md caused interface inconsistencies
- reason: Modified API but not updated CONTRACT.md
- consequence: The front-end call failed, and the troubleshooting was repeated 3 times.
- lesson: Any changes to the interface must be synchronized with doc/CONTRACT.md and contracts_baseline must be refreshed.
- remind / solution: Triggering the `contract-change` guardrail, executes `make contract_compat_check`.
```
---

#### **scripts目录**
该目录用于存放AI执行过程中生成的脚本或函数。每个脚本需要明确描述结构的注解或装饰器，便于导出规范。


临时开发的功能或脚本


这里需要补充示例

---
### 2.3 其他

**数据库**：需要在`interact/`目录下相应文档中声明的数据库操作包括：
- 新增或修改了表/表字段
- 函数、流程、脚本等会新增/删除/修改数值的情况

**测试**：需要在`interact/`目录下声明的测试信息包括：
- 测试数据的生成规则，包括mock和fixtrue
- 测试数据的格式、储存、生命周期的管理，包括mock和fixtrue
  
**接口协议**： 需要在`interact/`目录下声明的接口协议包括：
- 模块类型定义的对外暴露接口：这类接口是面向业务流程的，相当于模块实例和其他实例的交流通道
- 功能实现接口：功能可以为底层函数，也可以为串联好的工作流
- 服务之间的接口

**配置信息**
- 配置信息可能包含：{需要补充}
- 鼓励优先定义全局参数，而不是使用临时变量
- 模块实例需要维护自身的配置信息，项目也会维护一份高层的配置，出现同名时使用实例本地的配置。
- 示例结构如下：
```
config/
  ├── AGENTS.md           # 使用说明
  ├── db/                 # DB 连接、迁移策略
  ├── llm/                # 大模型 API、prompt bucket、温度/超参等接口参数
  ├── telemetry/          # 日志、metrics、alerts
  ├── parameters/         # 全局参数
  ├── prompts/            # 提示词模版、意图识别规则（按场景分类）
  ├── feature_flags/      # 开关、回滚策略
```
**人类阅读文档**：`docs/`目录的维护原则：
- 该目录一般由人类开发者自行维护
- 对模块的性能检查，维护报告等数据，不论是AI还是脚本的生成的，都应该指定路径，并放在目录下

---


## 3. AI工作流程

我们可以从AI编排的视角出发，看一看模板中包含的主要基础设施是否可以融入基于模块化思路的具体开发流程中。在获取任务后，AI编排周期的工作方式大致如下：
- 读取 `AGENTS.md` 中的任何必需策略
- 加载 `workdocs/` 目录下相关任务的上下文信息，加载必要的触发器
- 查阅 `ROUTING.md` 以定位相关知识文档
- 查阅 `ABILITY.md` 以识别合适的工具
- 执行开发，完成功能开发，将代码落实待正确的位置
- 更新 `workdocs/` 目录下的相关文档，记录决策过程和执行结果 

### 3.1 单一模块的功能开发
关于`workdocs/`目录的使用，我们已经在第二章中进行了介绍，而项目基础设施（如知识路由和功能路由等），我们将在第4章中给出协同说明。

由于AI是实际开发的主要主体，我们的首要目标是将项目模版的价值告诉AI，确保AI可以
- 理解模块的开发思想
- 知道有哪些可用的基础设施
- 要如何使用上下文目录
- ...

也就是说，对于模块内部的功能开发，`AGENTS.md`起到了至关重要的作用，我们需要：
- 确保阅读入口明确：在模块实例的根目录下维护实例级的`AGENTS.md` 
- 将AI需要的知道的各种内容整理成文档，并在`AGENTS.md`给出规范和策略的路由，Example： 补充一个示例


### 3.2 多个模块的联调测试

基于模块化开发思路，业务和数据链路被拆分成了多个模块间的链接关系，天然的适合自下而上的集成测试策略。然而，虽然以实例为对象进行维护提供了单模块内的功能开发边界，多模块实例的开发规范仍然容易发散，特别是对于AI而言。为了维持清晰的AI工作界限，模版要求
- 单个任务编排节点，必须限定在一个模块实例内
- 如果任务编排涉及多个模块实例，需要继续进行拆分
- 跨实例的任务编排，需要提供明确的流程指引

上述职责显然不应该属于某个具体的模块实例，所以需要有一套更加系统化的规范来应对多模块集成。典型的多模块实例的开发工作包括：性能评估、情景测试、bug修复、（这里可以补充其他情况）。我们将视角切换至应用场景：这些可以提供各式功能的模块，要如何与实际应用需求相结合。在模块实例完成了主要功能开发的前提下，提高跨实例任务执行效率的关键在于是否可以高效定位到问题。

我们需要一个可以承接跨模块贵发和具有上下文恢复能力的体系。基于第二章描述的模块实例的上下文目录`workdocs/`，我们在模块根目录`/modules/`延伸出了一个用于联调的子目录，通过同步关键内容帮助AI更好的完成跨模块任务的编排和实施。

#### 信息同步与维护

我们希望可以对项目的能力有一个全面的、可预判性的认知，从而可以在做集成、联调、bug修复等工作时，可以有的放矢。当我们定义好了明确的跨模块工作需求时，AI可以通过浏览这些信息，找到测试重点然后合理搭建测试环境。

**类型图结构**：
和文章开头的模块类型概念相对应，是项目所有模块类型的图结构。维护模块类型的图结构可以帮助梳理项目的数据流向，在多模块联调时可根据调试或集成需求，从类型维度筛选实例，从而明确流程。

对以下内容进行详细扩写：{
每个模块类型是图中的一个端点，端点的信息包括：

实例类型还需要维护有向边（从自己指向其他类型的，以及从其他类型指向自己的），这些边表明了实际业务中的可能存在的数据流向。

}

一个典型的模块类型的结构实例为：example（待补充）

同步方面，类型图结构的更新频率不高，仅在以下情况发生时才需要更新
- 有新模块类型加入项目时，需要将新的端点注册到类型图中，并根据业务需求提取数据流向，更新有向边；该情况一般在模块实例初始化的过程中检验。
- 新加入项目的模块类型和已有类型有业务往来、类型间的数据流向发生变化时候，需要更新类型图的有向边
- 当前接口被废弃、或有新的替代接口产生时，需要更新类型图的有向边
- 定义测试情形时发现类型图结构不支持，用户确认情景符合实际需求时，需要对类型图结构进行完善

**实例完成度**：
虽然每一个模块实例跟踪了自身的开发需求进度，但为了不必要的内容遍历，我们可以维护一个顶层的模块实例摘要，用于迅速了解各实例的主要职责、已完成的功能、整体进度等。
结构示例：example（待补充）

实例完成度需要定期更新，该过程可以集成到CI中进行：检查实例维护的上下文目录`workdocs/active/`是否发生变化。如果有任何里程碑式的节点被达成或重要功能被实现，则需要对实例完成度进行调整。

需要额外说明，`workdcos/archive/`目录是由CI机制进行维护的，也就是模块实例仅具备创建和更新的权限，而归档权限则属于项目级权限。每次进行上下文相关维护后，需要记录维护时间，如果维护时间晚于变更时间则说明没有变动。

**接口和网关**：

由于重点在于跨模块的联调或集成，所以文档需要维护的内容集中在每个模块实例的公共接口和网关上。模板要求以模块实例为单位，定期同步公共接口和网关的相关信息。

公共接口维度，模块实例需要和其所属的类型保持一致。相关信息我们已在**类型图结构**中进行了说明。

下述信息需要进行整合，增强可读性，并添加接口维护内容的结构示例：{

接口生命周期（状态）包括：

- DESIGNED：接口签名/协议已定型，已对齐前端/调用方的 Contract
- MOCKED：有Mock，但没实现实际业务，通过 Mock 服务或网关 Mock 返回固定响应
- IMPLEMENTED：已实现开发，单测/契约测试完整且没有失败
- QA_VERIFIED：测试环境验证通过，功能测试 / 契约测试 / 集成测试通过，已在测试环境对接真实上下游
- READY_FOR_RELEASE：已满足上线标准，待发布 / 灰度 （测试覆盖率、性能、安全扫描等），对应网关层将进入 canary/灰度状态
- RELEASED：已在生产可用（GA），稳定对外提供服务，有 SLA / 文档 / 监控
- SUNSET：下线中，流量逐步清零，新客户端/租户不再可访问，仅保留少量白名单/老客户端
- REMOVED：已彻底移除，实现和网关路由都下掉，文档只保留历史记录（如需）

质量状态包括：
- unit_test_status: NOT_RUN | FAILED | PASSED
- contract_test_status: NOT_RUN | FAILED | PASSED
- integration_test_status: NOT_RUN | FAILED | PASSED
- e2e_test_status: NOT_REQUIRED | FAILED | PASSED
- perf_test_status: NOT_REQUIRED | FAILED | PASSED
- security_scan_status: NOT_RUN | FAILED | PASSED

网关暴露范围：
- HIDDEN：不在任何正式入口暴露；仅内部工具可调（比如固定 IP/Token）
- INTERNAL：仅内部网络 / 内部应用可用
- PARTNER：仅合作方 / 特定租户可用
- PUBLIC：面对所有外部用户开放

网关流量策略

- DISABLED：路由存在，但不可访问，网关直接返回 404 / 410 / 自定义错误，用于快速下线或紧急熔断
- MOCK：网关层 Mock 响应，后端服务可选是否真正调用， 用于前期联调或后端不稳定时
- SHADOW：影子流量，用于验证新接口的兼容性和性能
- CANARY：灰度发布，按比例 / 用户 / 租户/Region 分流一部分流量
- LIMITED：限流 / 降级状态
- NORMAL：全量开放，无特殊限流（或仅普适限流）

网关健康度检验
- HEALTHY：错误率、延迟都在阈值内
- DEGRADED：有异常，但未到熔断标准（比如 P95 慢、但还可用）
- UNAVAILABLE：熔断/下线，网关按策略返回错误或降级响应
}

依据生命周期，我们规定公共接口的同步规则：
- 模块实例生成时或模块类型的接口新增时，需要加接口加入对应的模块实例下，并将其生命周期变为`DESIGNED`；
- 模块实例内部的开发过程中，需要对接口进行测试，根据测试情况，模块实例可以变更接口的生命周期至`MOCKED`或 `IMPLEMENTED`；
- 根据集成测试或情景测试的结果，项目允许百年更接口的生命周期至`QA_VERIFIED`或 `READY_FOR_RELEASE`
- `RELEASED`、 `SUNSET`、`REMOVED`仅允许人类开发人员手动修改

**情景维护**：

对以下信息进行概括/补全，然后总结成文档目标和格式示例：{

为了保障由AI主导的AI测试流程/环境和实际测试需求、用户使用流程相符合，我们要求先按照项目被用户实际使用的角度出发，定义情景或集成需求，就再进行测试。

相关测试包括：
- 单元测试（该步骤由模块实例自行完成）
  - 参数校验逻辑
  - 业务规则 & 状态机、幂等、去重逻辑
  - 异常处理和错误码映射
  - 对象转换 / 组装
- 契约测试
  - 接口签名
  - 请求结构、响应结构
  - 协同网关层进行测试
- 集成测试（单服务）
  - 接口到数据库的完整链路
  - 事务和一致性、缓存策略兼容性、消息发送格式和消费时的反序列化
  - 配置和框架集成、错误处理链路
- 集成测试（跨服务）
  - 服务间配置调用
  - 跨服务的数据流
  - 协议和序列化的一致性
  - 服务间的安全和鉴权集成
- 网关层测试
  - 路由正确性：确认“通过网关访问”的路径是通的，而且路由到的后端版本正确。
  - 鉴权和安全策略：确保网关层的 auth / ACL 插件或中间件配置正确。
  - 限流、熔断、超时/重试：验证“策略生效没配错”
- 端到端测试（情景测试）：走网关、覆盖完整业务流程，使用少量关键场景
  - 关键业务节点、关键负面链路、幂等/重试
  - 通过网关调用，真实路由、鉴权、限流等
  - 真实依赖，包括DB、MQ、Redis、上游下游
  - 跨服务和跨接口的一致性

多实例集成测试：
从系统完备性的角度来看，就需要定义功能组件的集成情景。这类情景和"接口通畅性"有紧密的关联，且一般不涉及网关。
我们需要确保所有相连的模块实例的链接在各种边际条件下畅通的，
涉及多个模块实例的调度/切换的（如TAB控制子界面、滚动显示不同模块实例等）等功能流程和操作逻辑正确

端到端的测试：
跨模块实例的任务很少是针对某个具体功能开发的，更要回答/解决的问题是：系统是否可以满足实际使用要求。
站在真实用户/真实客户端视角，验证关键业务流程能从入口通过网关一路跑到所有后端服务，数据和副作用都正确。
在小流量、真实环境下验证新版本的行为和老版本相比是否安全，包括：功能、兼容性、性能、稳定性

为描述清楚测试情形，规范的情景定义结构： example

}

将下述内容整理成情景内容的同步或维护时机：{

典型的，AI会根据用户输入，先到此文档中查询是否有对应的情况，再根据情景进展制定具体的测试策略。
对于没有形成情景的测试需求，要求AI先按照规范的结构，将测试需求转换成情景信息，并创建新的测试工作目录`modules/workdocs/<test_id>/`
本文档只维护情景的概述、测试时间、测试状态等基础显性信息，具体测试内容将在模块的根级`modules/workdocs/`目录下进行维护。

不论是集成测试还是端到端的测试，我们都需要和模块类型的图结构进行双向校验。如果测试情景涉及的数据流向在类型图结构中不存在通路，则需要和用户进行确认，决定是继续测试还是对图结构进行修改。

在进入集成测试之前，需要确保所有相关接口的生命周期已经具备了测试了条件。如无法进行情景测试，列出所有不满足条件的api接口，提示先在模块实例内完成接口的前序测试工作。
进入集成测试之后，需要检查对应测试情景的工作进度。当有里程碑测试节点完成时，在本文档中更新情景的测试状态。

}

**上下文维护**：

补完下述内容，形成目的性说明、必要的示例格式、以及更新/写入时机说明：{
和模块实例内的功能开发类似，AI在进行联调/集成测试的过程中也需要将关键信息记录下来。参考模块实例的`workdocs/`目录，我们将AI需要维护的内容分为`plan`、`context`、和`task`三个维度。

但是功能开发和测试的重点显然不同，例如规划阶段，我们需要根据需求确定...， 测试进行过程中，重点之一是发现问题并进行原因定位...，里程碑进度方面，也需要更加贴合测试的需求...

另一个需要注意的是，功能开发的流程一般是线性的，当遇到某个错误时，需要先解决错误再进行后续的开发。但测试工作本身就是要发现潜在的问题的，对于发现的问题，需要判断是否影响后续测试、是否严重到可以停止测试、还是说只需要将发现的错误进行记录。

我们将发现的错误情况（什么条件会发生什么的问题）纪录到`context.md`，一般情况下，我们还要求AI定位这些发现的原因，定位越清晰越好（至少需要定位到模块实例）。

}

#### 跨实例的任务工作流程

我们希望AI仍然可以成为联调测试的主要工作者，一个典型的AI联调流程大致如下

1. **明确需求**：根据用户输入，遍历情景文档中，
   - 如有正在进行的测试加载情景相关上下文，继续此前的工作
   - 如没有相关的情景，在上下文维护目录中创建新任务，更新情景文档
   - 如发现相关情景已完成测试，对此前的测试结果、完成时间、遗留问题等进行总结，再和用户进一步确认需求。
2. **任务分解**：
   - 构建测试流程、执行计划、生成测试数据（或生成规范）、定义里程碑节点等
   - 根据测试用的上下文写入规范，将分解的内容和规划写入相关文档
3. **上下文维护**：
   - 执行测试，并按照上下文维护规范
   - 检查是否有新完成的里程碑节点，如有则更新情景文档
   - 将所有发现错误和定位的原因，写入测试任务对应的`context.md`文档  
4. **修复**：
   - 在阶段性的测试结束或发现严重错误后，AI可以询问是否进行修复（也可以通过配置信息，改为自动修复）
   - 根据错误原因进行bug修复，修复时要具有全局视角，充分考虑相关影响，以免引发其他bug
   - 在修复成功后，总结修复方法、逻辑、以及效果，将内容写回测试的上下文维护文档中
5. **输出**
   - 在阶段性测试完成后，需要在情景文档中简要更新对应的测试情景中
   - 对于需要输出报告的，例如性能瓶颈等，将文档输出在测试任务目录的`outcome/`目录下

AI是否可以完成测试工作，取决于AI是否可以正确识别测试需求。为了增强AI对齐思路的能力，我们需要：
- 提供适合AI阅读的跨实例开发的规范和策略，并确保AI可以阅读到这份文档
- 开发脚手架工具，基于交互的方式收集足够的情景描述的必要信息，并确保AI的理解和测试需求具有一致性

**策略文档**
我们需要将module根级的`AGNETS.md`作为AI获取跨实例开发的规范和策略的顶层文档，明确其阅读入口的定位。需要注意，策略文档本身应该保持轻量化，内容应该以路由为主。路由指向独立维护的具体规范文档，文档包括：（补充完善）


**脚手架工具**
（补充完善）


此外，由于集成或联调的最终验收是由人类开发者完成的，项目在开发过程中会累积测试或可视化工具，这些工具并不会参与到AI的工作流程中，所以可以按照面向人类阅读和使用的方式进行维护。

#### 模块根目录骨架结构

基于上述信息，一个典型的模块根级目录的骨架结构如下：

```
modules/
├── AGENTS.md             # 根级策略文档
├── ROUNTING.md           # 顶层知识路由
├── routes/               # 具体知识路由
├── overview/             # 信息维护
│   ├── AGENTS.md         # 策略文档
│   ├── README.md         # 面向人类开发者
│   ├── type_registry.yaml       # 模块类型
│   ├── instance_registry.yaml   # 模块实例
│   ├── instance_maturity.yaml   # 模块实例完成度
│   ├── interfaces.yaml          # 接口信息
│   └── api_gateway.yaml         # 网关信息
├── intergration/         # 联调/集成
│   ├── AGENTS.md               # 联调策略文档
│   ├── ROUNTING.md             # 联调相关的知识路由
│   ├── ABILITY.md              # 联调相关的能力路由
│   ├── scenarios.yaml          # 情景说明
│   ├── workdocs/               # 当前进行的测试工作
│   │   ├── task-1/                 # 具体测试任务 - 和情景相对应
│   │   │   ├── task-1-plan.md      # 完成任务的计划
│   │   │   ├── task-1-context.md   # 记录工作上下文
│   │   │   └── task-1-task.md      # 任务完成情况和进度   
│   │   └── ...
│   ├── outcomes/         # 相关产出
│   │   ├── report/             # 具体测试任务 - 和情景相对应
│   │   └── ...
│   └── tools/            # 工具（例如可视化等）
├── config/               # 全局配置（可以补充）
│   ├── api_gateway/            # 网关配置
│   ├── parameters/             # 全局参数
│   ├── prompts/                # 提示词模版、意图识别规则（按场景分类）
└── 模式实例目录/          # 模块实例的具体实现

```

---

### 3.3 实例注册

#### 通过脚手架注册

模板将实现一个模块初始化的脚本，通过脚手架和注册表来维护模块生态系统的一致性。典型流程如下：
  1. 创建目录：创建`modules/<mod_id>/init/`，用于存放过程文档（如需求文档、必要信息记录、特殊要求等）以及充当创建期间的暂存区。该目录为临时目录，将在初始化流程结束后删除；
  1. 交互式信息收集：AI（或开发人员）将提供或被要求提供必要的详细信息，如模块领域、名称、类型和任何初始配置（如是否连接到数据库等）。
  2. 生成模块骨架：创建目录 modules/<mod_id>/，使用上面列出的文件填充它
  3. 注册模块实例：向模块注册表添加一个条目，结合前序步骤收集的信息和格式规范填写内容。
  4. 维护相关文档内容：类型关系图、根据描述可以接入的知识路由/能力路由等、策略文档、实例说明等
  5. 确认后，脚手架可以提示删除 init/ 文件夹并将模块标记为就绪。

#### "注册完成"的定义

初始化过程提供的是一个完全链接的模块，保证模块实例可以使用模板提供的各类基础设施。初始化仅要求骨架结构完整，允许真实逻辑为空，且不会提前编写任何业务逻辑。也就是说，基础设施的实际应用需要随着开发深入逐步完善。

在模块实例完成注册流程后，我们需要将这个新生成的模块实例的信息同步到各相关文件中。

- **实例信息**：实例的注册过程要求将注册成功实例加入到模块注册表中，该注册表是模块实例的SSOT。
- **类型关系图**：如果模块实例属于新的类型，即项目中还没有注册过相同类型的实例，我们需要进行模块类型的注册。
- **策略文档**：每个模块实例可能包含多个策略文档，起到帮助AI获取所需信息、规范AI工作流程的作用。同层级的`AGENTS.md`大体上是相似的，但仍然需要结合用户交互过程中收集的实际需求，进行一定程度上的调整
- **知识/能力路由**：待修改：参考第4章的知识路由协同以及能力路由协同，给出相关说明
- **说明类文档**：将模块实例的关键信息，整理后写入对应的文档

**其他事项**
- 层级：层级是模块的重要概念之一，但我们不需要额外维护模块层级关系，仅要求模块实例在注册过程中按规范填写`parent_module`和`module_level`字段。
- 模块移除/项目重构：删除模块应该是受控的操作：
  1. 通过类型图检查模块间的依赖关系，如果依赖关系复杂，需要手动批准才能继续
  2. 删除或重新分配模块所有的知识文档
  3. 检查模块包含的能力是否为专属能力，如是则删除能力
  4. 不允许一次操作中间同时重构或删除多个模块

---

## 4. 应用基础设施（infrastructure collaboration）

模块实例确定了AI任务编排节点的边界，模板中的基础设施（如知识路由、能力路由等）则用于提高AI的效能和一致性。为保障模块实例可以更好的履行该职责，我们需要规范模块实例和各类基础设施的联动。

### 4.1 知识路由的协同
我们将从应用和增强两个方面，分别讨论知识路由和模块实例开发的协同。

**应用**：
模块实例可以直接应用**知识路由**体系（详见<content_routing.md>）。实例目录维护的 `ROUTING.md`文档以及 `routes`目录，两者的作用分别为：
- `ROUTING.md`: 作为AI查询知识文档的入口，包含精简的scope/topic顶层索引，并给出每个topic对应的路由文件在哪里和大概是干什么的；
- `routes/` 目录：承接ROUTING.md的具体路由，使用`when_to_use` + `doc_usage`两层结构，每层级使用自然语言进行描述，最终指向知识文档地址

**增强**：
我们可以通过以下几个渠道，总结开发过程中好的技巧和工作流程，充实项目的知识文档池
- 归纳AI的工作过程：我们要求AI将做出的重要决策和从错误中学到的经验，分别记录到`workdocs/`目录下的文档`decisions.md`和`lessons.md`中。我们定期回顾和总结这些内容，检查是否可以形成的知识文档。
- 优化开发体验：虽然AI是主力开发，但人类开发则仍然需要投入到项目开发的全周期中，从需求的发起、AI的交流、得到的反馈、到功能的验收、整体进度的推进等，开发人员需要思考如何利用知识文档，和AI保持思想层面的一致性、帮助AI规避常见问题、提高代码一致性等

**总体而言**：
我们希望随着项目的深入，知识文档的深度和准度都可以得到积累，让AI能够在后续工作中输出质量更高且更符合设计需求的成果物。人类开发者需要在过程中，感知知识路由是否有效，并有意识的进行调整，使AI用起来更加顺手。
  
### 4.2 能力路由的协同
与知识路由类似，我们也将从应用和增强两个方面来讨论能力路由的协同。

**应用**：
我们在<ability_routing.md>文档中，详细解释了如何让AI复用脚本从而提高代码的一致性。例目录下的`ABILITY.md`给出了不同情景下的AI可以调用的工具。但和知识路由的 `ROUTING.md`文档不同，`ABILITY.md`不是强制限定能力的边界，实质上更像优先选择的建议。AI使用能力路由的流程示意如下：
1. AI依据任务编排，总结代码实现需求，加载相关知识和规范
2. 在`ABILITY.md`中查询是否有匹配需求的封装工具使用
3. 决定选择工具或是在工程包含的全量工具集中进一步检索
4. 选择调用工具或自行开发

模块实例本身的完成度和开发重心会随着项目深入而发生变化，我们可能需要动态维护`ABILITY.md`来调整AI的工具调用建议，进而使模块实例和能力路由的协同更加高效。
- 新模块实例：实例初始化完成后，会根据功能需求和项目的工具池来构建初始的`ABILITY.md`，形成基本的能力路由
- 开发阶段：每当模块实例需要新增功能、改变需求、或是工具池发生变化、发现更适合AI的工作模式时，都建议更新实例的`ABILITY.md`，提供更为清晰的指引

**增强**：
我们希望AI可以反馈其查找、使用、开发工具的过程，我们有两个主要的记录载体：
- `scripts/` 目录：如果不能在能力路由中找到合适的工具或方法，AI需要把符合规范的脚本文件放到目录下
- `decisions.md`：和知识文档的利用方式不同，我们会使用触发器的方式来记录AI对能力路由的使用情况。在AI阅读`ABILITY.md`时缓存AI工具使用需求，并监管后续的调用或生成。

通过归纳上述两个载体中和能力相关的内容，我们可以：
- 从可复用的角度出发，整合新开发的脚本或功能，然后将其加入能力路由
- 发现AI使用路由的习惯、调用工具的偏好、追踪效果，然后完善`ABILITY.md`

**总体而言**：
开发是动态变化的过程，我们需要将动态变化同步到能力路由体系中，所以需要定期
- 更新路由文档`ABILITY.md`，引导AI根据需求调用能力，起到提高AI决策效率和透明度的作用
- 检查`scripts/`目录下的新增功能，从项目层面考虑是否有需要整合到能录路由中
 
### 4.3 其他设施的协同

**策略协同**： AGENTS.md文档中定义的规范和执行策略遵循向上覆盖的原则
- 就地维护模块实例自身的需求或仅和实例有关联的说明/规则，可以直接在对应层级的`AGENTS.md`中写明，例如：整个实例都需要遵循的，写到实例根目录下的AGENTS.md，前端开发的策略和规范，写入实例前端目录下的策略文档。
  
**触发器协同**：由于触发器的作用对象是知识文档、封装后流程、路由信息等，其作用机制和模块化的开发方式没有显性冲突
- 面向知识文档的hook，主要通过用户输入来触发prompt匹配，提供上下文加载的路劲建议。具体流程可以参考`content_routing.md`
- 面向能力调用的hook，既可以通过用户输入来触发代码编辑类工具，也涉及通过工具调用的guardrail护栏机制
- 工作过程中的hook，一般是通过工具调用前后的（pre_tool_use和post_tool_use 机制）缓存，记录AI的决策意向和调用结果写入文档，用作后续分析



